---
title: Catalog Class
---

## Organizing Data with Catalog Class

Effective dataset organization is critical to maintain a productive analysis pipeline. Imagine if you could call specific data files or data directories from a function call anywhere in your analysis code? What if you could store this "catalog" in a simple, human-editable file, which can be accessed from a local folder or retrieved from a web link, without a complex database systems.

The `Catalog` class in the `signalfloweeg` module does exactly this! 

## An Example Catalog File
Let's look at an example of a Catalog file named `example_datasets.yaml` which can be edited in a text editor:

```yaml
# Catalog Name: Example
# Catalog Date: 1/3/2024
# Comments: assr = auditory steady state recording
# Template: "dataset label": "path" or "file"

demo_rest_state: "/srv/RAWDATA/exampledata/Resting/128_Rest_EyesOpen_D1004.set"
demo_auditory_chirp: "/srv/RAWDATA/exampledata/Chirp/128_Chirp_D0657_DIN8.set"
demo_auditory_assr: "/srv/RAWDATA/exampledata/SteadyState/"
```

You can make as many catalog files as you need - maybe one for each project or server. You could also use a single catalog file to store different stages or versions of a project. 

### What is the YAML text format?

YAML (YAML Ain't Markup Language) is a human-readable data format that is stored as a text file. It's a way to store and organize information in a structured and easy-to-understand way, similar to how you might organize information in a spreadsheet or a database. 

## How to use the Catalog Class

Let's say that you wanted to tally the number of epochs across two different auditory evoked datasets. Using the example above, you could do something like this:

```python
from signalfloweeg.catalog import Catalog

# Initialize the catalog
catalog = Catalog("example_datasets.yaml")

# Get the location of a dataset
data_folder1 = catalog.get_location("demo_auditory_chirp")
data_folder2 = catalog.get_location("demo_auditory_assr")

# Now you can use these locations to load your data and perform your analysis.

```

The method calls will return the file system path to the dataset. You can then use this path within your analysis code. 

## Usefulness of Abstracting the Data Location

By using dataset labels, you can easily change the underlying location of the dataset without having to modifications to your code. This is useful when developing code across different systems or sharing catalogs with others. 

## Creating a Catalog File

Let's return to our example catalog file:

```yaml
# Catalog Name: Example
# Catalog Date: 1/3/2024
# Comments: assr = auditory steady state recording
# Template: "dataset label": "path" or "file"

demo_rest_state: "/srv/RAWDATA/exampledata/Resting/128_Rest_EyesOpen_D1004.set"
demo_auditory_chirp: "/srv/RAWDATA/exampledata/Chirp/128_Chirp_D0657_DIN8.set"
demo_auditory_assr: "/srv/RAWDATA/exampledata/SteadyState/"
```

Let's break down the structure and usage of this template:

1. **Catalog Name and Date**: The first two lines provide metadata about the catalog, including the name and the date it was created. This information can be helpful for keeping track of different versions or iterations of your data catalog.

2. **Comments**: The third line allows you to add any relevant comments or notes about the datasets included in this catalog. In this example, the comment indicates that the "assr" datasets are related to auditory steady-state recordings.

3. **Template**: The template section is where you define the actual dataset information. Each dataset is represented by a key-value pair, where the "key" is the dataset label (e.g., `demo_rest_state`, `demo_auditory_chirp`, `demo_auditory_assr`) and the "value" is the file path or location of the dataset.

   - **Dataset Label**: The dataset label should be a descriptive and unique identifier for each dataset. These labels will be used to reference and access the datasets within your code.
   - **File Path or Location**: The value should be the full file path or location of the dataset. In this example, the paths are provided as absolute paths on a server (`/srv/RAWDATA/exampledata/...`), but they can also be relative paths or even file names if the datasets are located in a consistent directory structure.

To use this YAML template with the `Catalog` class, you would typically save the content as a text file (e.g., `example_catalog.yml`).

## Loading the Catalog File

To load the catalog file, you would use the `Catalog` class as shown below:

```python
from signalfloweeg.catalog import Catalog

catalog = Catalog(catalog_file='example_catalog.yml')
```

Or if you have stored the catalog file on a web server, you can load it from a URL:

```python
catalog = Catalog(catalog_url='https://example.com/example_catalog.yml')
```

## Exploring the Catalog

Once you have a `Catalog` instance, you can use its various methods to interact with the dataset information.

Here's a concise table summarizing the key functions of the `Catalog` class:

| Function | Description |
| --- | --- |
| `load_catalog` | Loads the catalog from a local or web-hosted YAML file. |
| `get_location` | Retrieves the file or folder path for a specific dataset. |
| `get_dataset_type` | Determines whether a dataset is a file or a folder. |
| `get_associated_fdt` | Checks for an associated FDT file for a `.SET` dataset. |
| `get_filelist` | Retrieves a list of files for a dataset, with optional filtering. |
| `summarize_filelist` | Provides a visual summary of the files associated with a dataset. |
| `create_yaml_template` | Generates a YAML template file with sample dataset information. |

This table provides a quick reference for the main functions available in the `Catalog` class, allowing you to easily identify the appropriate method for your data management needs.

## Specific Method Details

### Retrieving Dataset Locations

The `get_location` method allows you to retrieve the file or folder path associated with a specific dataset:

```python
# Get the location of a dataset
dataset_location = catalog.get_location("demo_rest_state")
print(dataset_location)
```

### Determining Dataset Types

The `get_dataset_type` method can be used to determine whether a dataset is a file or a folder:

```python
# Check the type of a dataset
dataset_type = catalog.get_dataset_type("proj_ketamine")
print(dataset_type)
```

### Checking for Associated FDT Files

If you have a dataset with a `.SET` extension, you can use the `get_associated_fdt_file` method to check if there is an associated FDT file:

```python
# Check for an associated FDT file
fdt_file_path, fdt_file_present = catalog.get_associated_fdt_file("demo_rest_state")
if fdt_file_present:
    print(f"Associated FDT file: {fdt_file_path}")
else:
    print("No associated FDT file found.")
```

### Retrieving File Lists

The `get_filelist` method allows you to retrieve a list of files associated with a specific dataset, optionally filtered by file extension, subfolder search, and filename regex:

```python
# Retrieve the files for a dataset, filtering by extension
dataset_files = catalog.get_filelist("demo_rest_state", extension=".set")
for file_info in dataset_files:
    print(f"Folder path: {file_info['folder_path']}")
    print(f"File name: {file_info['file_name']}")
    print(f"Extension: {file_info['extension']}")
    print()
```

### Summarizing File Lists

The `summarize_filelist` method provides a visual summary of the files associated with a dataset, including the total number of files, total size, and file type breakdown:

```python
# Summarize the files for a dataset
catalog.summarize_filelist()
```

### Creating a YAML Template

The `create_yaml_template` method allows you to generate a YAML template file with sample dataset names and file paths, which you can then customize with your own dataset information:

```python
# Create a YAML template file
catalog.create_yaml_template()
```

## Conclusion

The `Catalog` class provides a comprehensive set of tools for managing your EEG data files. By using this class, you can streamline your data loading process, ensure consistency across your analysis workflows, and improve the overall reproducibility of your research.